{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyM2F5stUp+OGGyge+VVcF3z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **PROJET DE GENERATION IA: DATA354/Construction d'un agent conversationnel**"],"metadata":{"id":"T0wMGNrkt5sk"}},{"cell_type":"markdown","source":["***Importation des Bibliotheques n√©cessaires.***"],"metadata":{"id":"hyAsG0-BvR8e"}},{"cell_type":"code","source":["!pip install -q streamlit pyngrok langchain-huggingface langchain faiss-cpu sentence-transformers beautifulsoup4 requests langchain-community"],"metadata":{"id":"octz_oGmt4CN","executionInfo":{"status":"ok","timestamp":1742326547138,"user_tz":-60,"elapsed":5115,"user":{"displayName":"Cecile Tsague","userId":"06503288641698813372"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# *Code pour l'application √† deployer: ce code inclut de scrapping; l'insertion du modele \"Minstral\" et implementation du chatbot*"],"metadata":{"id":"rgkHozFBvh13"}},{"cell_type":"code","source":["%%writefile app.py\n","import os\n","import requests\n","import streamlit as st\n","import json\n","from bs4 import BeautifulSoup\n","from langchain.schema import Document\n","from langchain.vectorstores import FAISS\n","from langchain.embeddings import HuggingFaceEmbeddings\n","from langchain.chains import RetrievalQA\n","from langchain_huggingface import HuggingFaceEndpoint\n","\n","# üìå D√©finition du mod√®le IA\n","HF_TOKEN = os.getenv(\"HF_TOKEN\", \"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\")\n","MODEL_ID = \"mistralai/Mistral-7B-Instruct-v0.3\"\n","\n","# üìå Chargement du mod√®le Hugging Face\n","llm = HuggingFaceEndpoint(\n","    repo_id=MODEL_ID,\n","    task=\"text-generation\",\n","    huggingfacehub_api_token=HF_TOKEN,\n","    max_new_tokens=1024,\n","    do_sample=True,\n","    temperature=0.95,\n","    top_p=0.95\n",")\n","\n","# üìå Fonction pour scraper les articles\n","def scrape_articles(url):\n","    try:\n","        response = requests.get(url, timeout=10)\n","        response.raise_for_status()\n","    except requests.RequestException as e:\n","        st.error(f\"üö® Erreur lors de l'acc√®s √† {url} : {e}\")\n","        return []\n","\n","    soup = BeautifulSoup(response.content, 'html.parser')\n","    links = {a['href'] for a in soup.find_all('a', href=True)}\n","\n","    articles = []\n","    for link in links:\n","        if any(social in link for social in [\"facebook\", \"twitter\", \"linkedin\", \"instagram\", \"mailto\"]):\n","            continue\n","\n","        full_link = link if link.startswith(\"http\") else url + link\n","        try:\n","            article_response = requests.get(full_link, timeout=10)\n","            article_response.raise_for_status()\n","            article_soup = BeautifulSoup(article_response.content, 'html.parser')\n","\n","            title = article_soup.find('h1')\n","            title = title.get_text(strip=True) if title else \"Titre non trouv√©\"\n","\n","            content = \" \".join([p.get_text(strip=True) for p in article_soup.find_all('p')])\n","            if content:\n","                articles.append(Document(page_content=f\"{title}\\n\\n{content}\", metadata={\"url\": full_link}))\n","        except requests.RequestException:\n","            continue\n","\n","    return articles\n","\n","# üìå URL de la page √† scraper\n","base_url = \"https://www.agenceecofin.com/\"\n","documents = scrape_articles(base_url)\n","\n","if documents:\n","    # üìå Enregistrement des documents scrapp√©s dans un fichier\n","    articles_data = [{\"title\": doc.page_content.split(\"\\n\")[0], \"url\": doc.metadata[\"url\"], \"content\": doc.page_content} for doc in documents]\n","\n","    with open(\"documents_scrapes.json\", \"w\", encoding=\"utf-8\") as f:\n","        json.dump(articles_data, f, ensure_ascii=False, indent=4)\n","\n","    # üìå Cr√©ation des embeddings\n","    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n","\n","    # üìå Indexation FAISS\n","    vectorstore = FAISS.from_documents(documents, embeddings)\n","\n","    # üìå Cr√©ation du chatbot avec RetrievalQA\n","    qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=vectorstore.as_retriever(), return_source_documents=True)\n","\n","    # üìå Interface utilisateur avec Streamlit\n","    st.title(\"ü§ñ Chatbot IA bas√© sur RAG\")\n","    st.write(\"Bienvenue sur votre agent conversationnel, veuillez me poser votre question.\")\n","\n","    question = st.text_input(\"Posez votre question ici :\")\n","    if st.button(\"üîç Obtenir une r√©ponse\"):\n","        if question:\n","            with st.spinner(\"üí° G√©n√©ration de la r√©ponse...\"):\n","                result = qa_chain(question)\n","                response_text = result[\"result\"]\n","                source_docs = result[\"source_documents\"]\n","\n","            st.markdown(\"### üìù R√©ponse :\")\n","            st.write(response_text)\n","\n","            # Affichage des sources utilis√©es\n","            if source_docs:\n","                st.markdown(\"### üìö Sources utilis√©es :\")\n","                for doc in source_docs:\n","                    if \"url\" in doc.metadata:\n","                        st.markdown(f\"- [{doc.metadata['url']}]({doc.metadata['url']})\")\n","                    else:\n","                        st.markdown(\"- Source inconnue\")\n","    else:\n","        st.warning(\"‚ö†Ô∏è Veuillez entrer une question.\")\n","\n","    # üìå Bouton de t√©l√©chargement des documents scrapp√©s\n","    st.download_button(\n","        label=\"üì• T√©l√©charger les articles scrapp√©s\",\n","        data=json.dumps(articles_data, ensure_ascii=False, indent=4),\n","        file_name=\"articles_scrapes.json\",\n","        mime=\"application/json\"\n","    )\n","else:\n","    st.warning(\"‚ö†Ô∏è Aucun article n'a √©t√© r√©cup√©r√©. V√©rifiez l'URL ou le site source.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9oHtS1Iot7n7","executionInfo":{"status":"ok","timestamp":1742326557777,"user_tz":-60,"elapsed":23,"user":{"displayName":"Cecile Tsague","userId":"06503288641698813372"}},"outputId":"f4606e88-bcd3-42d4-8fc9-3bfadfaef539"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting app.py\n"]}]},{"cell_type":"code","source":["!pip install pyngrok\n","\n","from pyngrok import ngrok\n","import subprocess\n","import os\n","\n","# Get your authtoken from https://dashboard.ngrok.com/auth\n","NGROK_AUTH_TOKEN = \"2uUD02oPbJkEQuUHMR8vaXBK1j1_5zzG7r8FE1pTnz9ivUNG8\"  # Replace with your actual authtoken\n","os.environ[\"NGROK_AUTH_TOKEN\"] = NGROK_AUTH_TOKEN #Setting the authtoken as environment variable\n","\n","ngrok.set_auth_token(NGROK_AUTH_TOKEN)  # Set the authtoken\n","\n","# Lancer ngrok sur le port 8501 (port par d√©faut de Streamlit)\n","# The port argument should be an integer\n","public_url = ngrok.connect(8501)  # Changed from port=\"8501\" to port=8501\n","print(\"üåç Acc√©dez √† votre application ici :\", public_url)\n","\n","# Lancer Streamlit\n","subprocess.run([\"streamlit\", \"run\", \"app.py\"])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u6W2VvBauUlj","outputId":"078f7bd4-d106-404b-ba9d-f321b11d6d91"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.3)\n","Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n","üåç Acc√©dez √† votre application ici : NgrokTunnel: \"https://3458-34-106-146-191.ngrok-free.app\" -> \"http://localhost:8501\"\n"]}]},{"cell_type":"markdown","source":["***üåç Acc√©dez √† votre application ici : NgrokTunnel: \"Cliquez sur le lien 'https://....etc' ci-dessus***"],"metadata":{"id":"F9Z4oQg0wb6n"}}]}